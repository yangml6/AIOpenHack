{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_57_input to have 4 dimensions, but got array with shape (3819, 97200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ad0be8129c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mlabelprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mlabelprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mloss_and_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_and_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-ad0be8129c60>\u001b[0m in \u001b[0;36mKerasmodel\u001b[0;34m(x, y, xx, yy)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;31m#     model.fit(x, y, epochs=5, batch_size=32, verbose=1, validation_data=(xx, yy))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1638\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1481\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1484\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1485\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_57_input to have 4 dimensions, but got array with shape (3819, 97200)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from PIL import Image\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def travel(orgpth,img=[],label=[]):\n",
    "    fs = os.listdir(orgpth)  \n",
    "    for f in fs:\n",
    "        tmp_path = os.path.join(orgpth, f)\n",
    "        if not os.path.isdir(tmp_path):  \n",
    "#             print('do with file: %s'%tmp_path)\n",
    "            img_0,label_0 = processfile(tmp_path)\n",
    "            img.append(img_0)\n",
    "            label.append(label_0)\n",
    "        else:\n",
    "#             print('do with dir: %s'%tmp_path)\n",
    "            travel(tmp_path,img,label)\n",
    "    \n",
    "def readarray(im_pth,img=[],label=[]):   \n",
    "    travel(im_pth,img,label)\n",
    "    n_img = np.array(img)\n",
    "    return n_img,label\n",
    "\n",
    "def labelprocess(y):\n",
    "    for index, value in enumerate(y):\n",
    "        if value=='axes':y[index]=0\n",
    "        if value=='boots':y[index]=1\n",
    "        if value=='carabiners':y[index]=2          \n",
    "        if value=='crampons':y[index]=3\n",
    "        if value=='gloves':y[index]=4\n",
    "        if value=='hardshell_jackets':y[index]=5\n",
    "        if value=='harnesses':y[index]=6\n",
    "        if value=='helmets':y[index]=7\n",
    "        if value=='insulated_jackets':y[index]=8\n",
    "        if value=='pulleys':y[index]=9\n",
    "        if value=='rope':y[index]=10\n",
    "        if value=='tents':y[index]=11\n",
    "    y = np_utils.to_categorical(y, 12) \n",
    "\n",
    "def processfile(im_pth):\n",
    "    im = Image.open(im_pth)\n",
    "    imarray = np.asarray(im, dtype=np.uint8)\n",
    "    n_imarray = imarray.flatten()\n",
    "    label = im_pth.split('/')[-2]\n",
    "#     pca = PCA(n_components=2)  \n",
    "#     n_imarray = pca.fit_transform(imarray)\n",
    "#     PCA(copy=True, n_components=2, whiten=False) \n",
    "#     print(n_imarray,n_imarray.shape)\n",
    "#     print(im_pth.split('/')[-2])\n",
    "#     print(flatten_im.shape,n_imarray.shape)\n",
    "    return n_imarray,label\n",
    "\n",
    "def Kerasmodel(x,y,xx,yy):\n",
    "    model = Sequential() \n",
    "  \n",
    "    model.add(Dense(512, input_shape=(128,128,3)))  \n",
    "    model.add(Conv2D(32, (4, 4), input_shape=(128,128,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "    model.add(Conv2D(32, (4, 4)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5))) \n",
    "    model.add(Dense(1, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "\n",
    "    # x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "    model.fit(x, y, epochs=5, batch_size=32)\n",
    "#     model.fit(x, y, epochs=5, batch_size=32, verbose=1, validation_data=(xx, yy))\n",
    "\n",
    "    # model.train_on_batch(x_batch, y_batch)\n",
    "    loss_and_metrics = model.evaluate(xx, yy, batch_size=32)\n",
    "    classes = model.predict(xx, batch_size=32)\n",
    "    \n",
    "    return loss_and_metrics, classes\n",
    "\n",
    "\n",
    "im_pth = \"gear_images_a\"\n",
    "readarray(im_pth)\n",
    "img,label = readarray(im_pth)\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(img, label, test_size=0.1, random_state=0)\n",
    "labelprocess(Y_train)\n",
    "labelprocess(Y_test)\n",
    "loss_and_metrics, classes = Kerasmodel(X_train, Y_train, X_test, Y_test)\n",
    "print(loss_and_metrics, '\\n', classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
